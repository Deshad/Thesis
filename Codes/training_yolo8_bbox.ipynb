{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--device DEVICE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\2955352g\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3f6a330ff864cd2b490011f1ac843288765bd2e7e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2955352g\\.conda\\envs\\tf_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "DATA_ROOT = Path(\"C:/Users/2955352g/Desktop/pig_data_edinburgh\")\n",
    "\n",
    "class AnnotatedDataGenerator(Sequence):\n",
    "    \"\"\"Data generator for annotated frames to avoid memory issues\"\"\"\n",
    "    \n",
    "    def __init__(self, data_info, batch_size=8, target_size=(224, 224), shuffle=True):\n",
    "        self.data_info = data_info\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(data_info))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data_info) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_data = [self.data_info.iloc[i] for i in batch_indices]\n",
    "        \n",
    "        X, y = self._load_batch(batch_data)\n",
    "        return X, y\n",
    "    \n",
    "    def _load_batch(self, batch_data):\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for data in batch_data:\n",
    "            try:\n",
    "                # Load frame from video\n",
    "                cap = cv2.VideoCapture(str(data['video_path']))\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, data['frame_num'])\n",
    "                ret, frame = cap.read()\n",
    "                cap.release()\n",
    "                \n",
    "                if ret:\n",
    "                    # Resize frame\n",
    "                    frame = cv2.resize(frame, self.target_size)\n",
    "                    frame = frame.astype(np.float32) / 255.0  # Normalize\n",
    "                    X.append(frame)\n",
    "                    y.append(data['behavior_encoded'])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading frame: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "class YOLOv8Detector:\n",
    "    def __init__(self, model_path=None, device='auto'):\n",
    "        \"\"\"\n",
    "        Initialize YOLOv8 detector\n",
    "        :param model_path: Path to custom trained YOLOv8 model (.pt file)\n",
    "        :param device: 'cpu' or 'cuda' or 'auto'\n",
    "        \"\"\"\n",
    "        if model_path is None:\n",
    "            # Load default COCO-pretrained model\n",
    "            self.model = YOLO('yolov8n.pt')\n",
    "        else:\n",
    "            # Load custom trained model\n",
    "            self.model = YOLO(model_path)\n",
    "        \n",
    "        # Set device\n",
    "        self.device = device\n",
    "    \n",
    "    def train(self, data_yaml, epochs=50, imgsz=640, batch=16):\n",
    "        \"\"\"\n",
    "        Train YOLOv8 model\n",
    "        :param data_yaml: Path to data.yaml file\n",
    "        :param epochs: Number of training epochs\n",
    "        :param imgsz: Image size\n",
    "        :param batch: Batch size\n",
    "        \"\"\"\n",
    "        results = self.model.train(\n",
    "            data=data_yaml,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch,\n",
    "            device=self.device,\n",
    "            pretrained=True,\n",
    "            optimizer='auto',\n",
    "            lr0=0.01,\n",
    "            patience=10\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def detect(self, frame, conf=0.5, iou=0.4):\n",
    "        \"\"\"\n",
    "        Detect pigs in a frame\n",
    "        :param frame: Input frame (BGR format)\n",
    "        :param conf: Confidence threshold\n",
    "        :param iou: IoU threshold for NMS\n",
    "        :return: List of detections [x1, y1, x2, y2, conf, cls]\n",
    "        \"\"\"\n",
    "        # Convert frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Run inference\n",
    "        results = self.model.predict(\n",
    "            frame_rgb,\n",
    "            conf=conf,\n",
    "            iou=iou,\n",
    "            device=self.device,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Extract bounding boxes\n",
    "        detections = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            confs = result.boxes.conf.cpu().numpy()\n",
    "            cls_ids = result.boxes.cls.cpu().numpy()\n",
    "            \n",
    "            for box, conf, cls_id in zip(boxes, confs, cls_ids):\n",
    "                detections.append({\n",
    "                    'bbox': [int(box[0]), int(box[1]), int(box[2]-box[0]), int(box[3]-box[1])],  # Convert to [x,y,w,h]\n",
    "                    'confidence': float(conf),\n",
    "                    'class_id': int(cls_id)\n",
    "                })\n",
    "        \n",
    "        return detections\n",
    "\n",
    "def load_annotated_data_info():\n",
    "    \"\"\"Load annotated data information without loading frames into memory\"\"\"\n",
    "    data_info = []\n",
    "    \n",
    "    # Check if annotated directory exists\n",
    "    annotated_dir = DATA_ROOT / \"annotated\"\n",
    "    if not annotated_dir.exists():\n",
    "        print(f\"Warning: Annotated directory {annotated_dir} does not exist\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    json_files = list(annotated_dir.rglob(\"output.json\"))\n",
    "    if not json_files:\n",
    "        print(\"No output.json files found in annotated directory\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"Found {len(json_files)} annotation files\")\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file) as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            video_path = json_file.parent / \"color.mp4\"\n",
    "            if not video_path.exists():\n",
    "                print(f\"Warning: Video file {video_path} does not exist\")\n",
    "                continue\n",
    "            \n",
    "            # Quick check if video can be opened\n",
    "            cap = cv2.VideoCapture(str(video_path))\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Warning: Cannot open video {video_path}\")\n",
    "                continue\n",
    "            \n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            cap.release()\n",
    "            \n",
    "            print(f\"Processing {video_path} with {total_frames} frames\")\n",
    "            \n",
    "            for obj in data.get('objects', []):\n",
    "                for frame_data in obj.get('frames', []):\n",
    "                    frame_num = frame_data.get('frameNumber', 0)\n",
    "                    if frame_num >= total_frames:\n",
    "                        continue\n",
    "                    \n",
    "                    # Handle different bbox formats\n",
    "                    bbox = frame_data.get('bbox', [0, 0, 100, 100])\n",
    "                    \n",
    "                    # Debug: Print first few bbox formats\n",
    "                    if len(data_info) < 3:\n",
    "                        print(f\"  Sample bbox: {bbox}, type: {type(bbox)}\")\n",
    "                    \n",
    "                    # Normalize bbox format\n",
    "                    try:\n",
    "                        if isinstance(bbox, str):\n",
    "                            import ast\n",
    "                            bbox = ast.literal_eval(bbox)\n",
    "                        \n",
    "                        if isinstance(bbox, dict):\n",
    "                            # Convert dict format to list [x, y, width, height]\n",
    "                            x = bbox.get('x', 0)\n",
    "                            y = bbox.get('y', 0)\n",
    "                            w = bbox.get('width', bbox.get('w', 100))\n",
    "                            h = bbox.get('height', bbox.get('h', 100))\n",
    "                            bbox = [x, y, w, h]\n",
    "                        \n",
    "                        # Ensure bbox is a list with 4 elements\n",
    "                        if not isinstance(bbox, (list, tuple)) or len(bbox) != 4:\n",
    "                            bbox = [0, 0, 100, 100]\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing bbox {bbox}: {e}\")\n",
    "                        bbox = [0, 0, 100, 100]\n",
    "                    \n",
    "                    data_info.append({\n",
    "                        'video_path': str(video_path),\n",
    "                        'behavior': frame_data.get('behaviour', 'unknown'),\n",
    "                        'bbox': bbox,\n",
    "                        'video_id': json_file.parent.name,\n",
    "                        'date': json_file.parent.parent.name,\n",
    "                        'frame_num': frame_num\n",
    "                    })\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Found {len(data_info)} annotated frames\")\n",
    "    return pd.DataFrame(data_info)\n",
    "\n",
    "def prepare_yolo_dataset(data_info, output_dir):\n",
    "    \"\"\"\n",
    "    Prepare dataset in YOLOv8 format\n",
    "    :param data_info: DataFrame with annotation info\n",
    "    :param output_dir: Directory to save YOLO dataset\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    (output_dir / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (output_dir / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create data.yaml\n",
    "    data_yaml = {\n",
    "        'path': str(output_dir.absolute()),\n",
    "        'train': 'images',\n",
    "        'val': 'images',\n",
    "        'names': ['pig'],\n",
    "        'nc': 1\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / 'data.yaml', 'w') as f:\n",
    "        yaml.dump(data_yaml, f)\n",
    "    \n",
    "    # Process each frame\n",
    "    for idx, row in data_info.iterrows():\n",
    "        try:\n",
    "            # Load frame\n",
    "            cap = cv2.VideoCapture(str(row['video_path']))\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, row['frame_num'])\n",
    "            ret, frame = cap.read()\n",
    "            cap.release()\n",
    "            \n",
    "            if not ret:\n",
    "                continue\n",
    "                \n",
    "            # Save image\n",
    "            img_path = output_dir / 'images' / f\"{row['video_id']}_{row['frame_num']}.jpg\"\n",
    "            cv2.imwrite(str(img_path), frame)\n",
    "            \n",
    "            # Prepare YOLO annotation\n",
    "            bbox = row['bbox']\n",
    "            if isinstance(bbox, str):\n",
    "                bbox = ast.literal_eval(bbox)\n",
    "            if isinstance(bbox, dict):\n",
    "                x = bbox.get('x', 0)\n",
    "                y = bbox.get('y', 0)\n",
    "                w = bbox.get('width', bbox.get('w', 100))\n",
    "                h = bbox.get('height', bbox.get('h', 100))\n",
    "                bbox = [x, y, w, h]\n",
    "            \n",
    "            # Convert to YOLO format (normalized cx, cy, w, h)\n",
    "            img_h, img_w = frame.shape[:2]\n",
    "            x_center = (bbox[0] + bbox[2]/2) / img_w\n",
    "            y_center = (bbox[1] + bbox[3]/2) / img_h\n",
    "            width = bbox[2] / img_w\n",
    "            height = bbox[3] / img_h\n",
    "            \n",
    "            # Save label\n",
    "            label_path = output_dir / 'labels' / f\"{row['video_id']}_{row['frame_num']}.txt\"\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(f\"0 {x_center} {y_center} {width} {height}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "def train_yolov8_detector(data_info, output_dir='yolo_dataset', device='auto'):\n",
    "    \"\"\"\n",
    "    Train YOLOv8 detector on pig data\n",
    "    :param data_info: DataFrame with annotation info\n",
    "    :param output_dir: Directory to save YOLO dataset\n",
    "    :param device: 'cpu', 'cuda', or 'auto'\n",
    "    :return: Trained YOLOv8 detector\n",
    "    \"\"\"\n",
    "    # Prepare YOLO format dataset\n",
    "    prepare_yolo_dataset(data_info, output_dir)\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = YOLOv8Detector(device=device)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training YOLOv8 detector...\")\n",
    "    results = detector.train(\n",
    "        data_yaml=str(Path(output_dir) / 'data.yaml'),\n",
    "        epochs=50,\n",
    "        imgsz=640,\n",
    "        batch=-1  # Auto batch size\n",
    "    )\n",
    "    \n",
    "    return detector\n",
    "\n",
    "def run_full_pipeline(device='auto'):\n",
    "    print(\"Starting pig behavior detection pipeline...\")\n",
    "    \n",
    "    # Check if data directory exists\n",
    "    if not DATA_ROOT.exists():\n",
    "        print(f\"Error: Data directory {DATA_ROOT} does not exist\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(\"Loading data information...\")\n",
    "    data_info = load_annotated_data_info()\n",
    "    \n",
    "    if data_info.empty:\n",
    "        print(\"No annotated data found. Cannot proceed with training.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(\"Training YOLOv8 detector...\")\n",
    "    detector = train_yolov8_detector(data_info, device=device)\n",
    "    \n",
    "    print(\"Initializing tracker...\")\n",
    "    tracker = PigTracker()\n",
    "    \n",
    "    print(\"Training behavior classifier...\")\n",
    "    behavior_model, behavior_mapping = train_behavior_classifier(data_info)\n",
    "    \n",
    "    print(\"Pipeline training complete!\")\n",
    "    return detector, tracker, behavior_model\n",
    "\n",
    "def test_single_video(detector, behavior_model, video_path):\n",
    "    \"\"\"Test the trained models on a single video\"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video file {video_path} does not exist\")\n",
    "        return\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:  # Process every 30th frame\n",
    "            # Get detections\n",
    "            if detector:\n",
    "                detections = detector.detect(frame)\n",
    "                print(f\"Frame {frame_count}: Detected {len(detections)} pigs\")\n",
    "                for det in detections:\n",
    "                    print(f\"  Bbox: {det['bbox']}, Confidence: {det['confidence']:.2f}\")\n",
    "            \n",
    "            # Get behavior (resize frame first)\n",
    "            if behavior_model:\n",
    "                frame_resized = cv2.resize(frame, (224, 224))\n",
    "                frame_norm = frame_resized.astype(np.float32) / 255.0\n",
    "                frame_batch = np.expand_dims(frame_norm, axis=0)\n",
    "                \n",
    "                behavior_pred = behavior_model.predict(frame_batch, verbose=0)\n",
    "                behavior_class = np.argmax(behavior_pred[0])\n",
    "                confidence = np.max(behavior_pred[0])\n",
    "                print(f\"Frame {frame_count}: Behavior class: {behavior_class}, Confidence: {confidence:.3f}\")\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"Processed {frame_count} frames\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--device', type=str, default='auto', help=\"Device to use: 'cpu', 'cuda', or 'auto'\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    detector, tracker, behavior_model = run_full_pipeline(device=args.device)\n",
    "    \n",
    "    if detector is not None:\n",
    "        print(\"Detection model trained successfully\")\n",
    "    if behavior_model is not None:\n",
    "        print(\"Behavior classification model trained successfully\")\n",
    "    if tracker is not None:\n",
    "        print(\"Tracker initialized successfully\")\n",
    "    \n",
    "    # Test on a single video if models are trained\n",
    "    if detector or behavior_model:\n",
    "        test_video_path = DATA_ROOT / \"annotated\" / \"test_video.mp4\"  # Adjust path as needed\n",
    "        if test_video_path.exists():\n",
    "            test_single_video(detector, behavior_model, str(test_video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
